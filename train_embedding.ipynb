{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Apr  2 12:37:54 2020\n",
    "\n",
    "@author: mor\n",
    "\"\"\"\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from gensim.models.word2vec import LineSentence\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import codecs\n",
    "import string\n",
    "import subprocess\n",
    "import unicodedata\n",
    "import os\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE = os.getcwd()\n",
    "DATA = os.path.join(BASE,'data')\n",
    "MODELS = os.path.join(BASE,'models')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# train Word2Vec, FastText, Doc2Vec\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# train Word2Vec\n",
    "# ============================================================================= \n",
    "def train(inp = DATA+\"/texts.txt\",out_model = MODELS+\"/word2vec.model\"):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    model = Word2Vec(LineSentence(inp), sg = 1, # 0=CBOW , 1= SkipGram\n",
    "                     size=100, window=5, min_count=5, workers=multiprocessing.cpu_count())\n",
    "\n",
    "    # trim unneeded model memory = use (much) less RAM\n",
    "    model.init_sims(replace=True)\n",
    "\n",
    "    print(time.time()-start)\n",
    "\n",
    "    model.save(out_model)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# train FastText\n",
    "# =============================================================================    \n",
    "def trainFastText(inp = DATA+\"/texts.txt\",out_model = MODELS+\"/fasttext.model\"):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    model = FastText(LineSentence(inp) ,sg = 1, # 0=CBOW , 1= SkipGram\n",
    "                     size=100, window=5, min_count=5, workers=multiprocessing.cpu_count())\n",
    "\n",
    "    # trim unneeded model memory = use (much) less RAM\n",
    "    model.init_sims(replace=True)\n",
    "\n",
    "    print(time.time()-start)\n",
    "\n",
    "    model.save(out_model)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# =============================================================================\n",
    "# load models\n",
    "# =============================================================================\n",
    "modelWord2Vec =  Word2Vec.load(MODELS+\"/word2vec.model\")\n",
    "modelFastText =  FastText.load(MODELS+\"/fasttext.model\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# train doc2vec\n",
    "# ============================================================================= \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df = pd.read_csv(DATA+'/cases.csv')\n",
    "    \n",
    "data = df[['id','text']].values\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(d[1]), tags=[d[0]]) for d in data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train model\n",
    "max_epochs = 100\n",
    "vec_size = 200\n",
    "alpha = 0.025\n",
    "\n",
    "def train_doc2vec(tagged_data,max_epochs=100,vec_size=200,alpha=0.025,workers=4, path=MODELS+\"/doc2vec.model\"):\n",
    "\n",
    "    model = Doc2Vec(vector_size=vec_size,\n",
    "                    alpha=alpha, \n",
    "                    min_alpha=0.00025,\n",
    "                    min_count=1,\n",
    "                    dm =1,#'distributed memory' (PV-DM)\n",
    "                    workers=4)\n",
    "      \n",
    "    model.build_vocab(tagged_data)\n",
    "    \n",
    "    for epoch in range(max_epochs):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "        model.train(tagged_data,\n",
    "                    total_examples=model.corpus_count,\n",
    "                    epochs=model.iter)\n",
    "        # decrease the learning rate\n",
    "        model.alpha -= 0.0002\n",
    "        # fix the learning rate, no decay\n",
    "        model.min_alpha = model.alpha\n",
    "    \n",
    "    model.save(path)\n",
    "    print(\"Model Saved\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# load model\n",
    "# =============================================================================\n",
    "model = Doc2Vec.load(MODELS+\"/doc2vec.model\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
